{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MamatkulovBunyodbek1999/SQL-DATABASE/blob/main/3_1_BOLIM_MALUMOTLARGA_ISHLOV_BERISH_DATA_BASE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gfca4L7AkzTn"
      },
      "source": [
        "3-PART. CLEANING DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1hX267Yks7N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import Series \n",
        "import sqlite3 as sql\n",
        "from pprint import pprint as print"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLZuArEMJRDV"
      },
      "source": [
        "read_csv : comma separated values.(in order to work with files which are separeted with commas)\n",
        "read_excel : excel files\n",
        "\n",
        "To import files from github repos  (trough \"raw\" button) copy the link and import the files by the help of this method[!wget link]\n",
        "\n",
        "( !git clone https://...fileName... ) This method helps to import files from github repositories,through the link which has been copied from github repos window "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPdFFW_ClCR9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raPnXj-zNB23"
      },
      "source": [
        "fayllarni dataframe ko'rinishida ochish uchun esa : df=pd.read_csv(\"https:fayl...nimi\") korinishida yozishimiz kerak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yciTYQAyNiUW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "polTBEnPNlkp"
      },
      "source": [
        "Papkani ichiddan faylni chaqirib olish uchun esa: df=read_csv(\"papkaNomi/FaylNomi\") papka nomidan so'ng slash orqali / fayl nomi yozilishi kerak.\n",
        "\n",
        "to import a file from a folder, we need to put slash / right after the  folder name and and write the file name that we need.\n",
        "df=read_csv(\"FolderName/FileName\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT2EI6suOdaq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph4FM4B-QMrc"
      },
      "source": [
        "Fayllarni ochish jarayonida ustunlarni nomini ham o'zgartirishimiz yoki malum bir ustunni index sifatida((index_col=0) nolni o'rnida ustun indexi yoki nomi qo'shtrnoq ichida \"ustun  nomi \" yozilishi kifoya qiladi) orqali chaqirishimiz mumkin:\n",
        "df=pd.read_csv(\"fayl/nomi\" index_col=0)\n",
        "\n",
        "While opening a file, we can set a certain [column] as an index>>(index_col=2 {instead of 2 can be any column index OR columnName}) OR change [column] names:\n",
        "[ df=pd.read_csv(\"fileName\" index_col=0) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cAD_7v5RiBX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsOwjkNBRi8f"
      },
      "source": [
        "Hattoki ustunlarni ham nomini o'zgartirib(names=[\"ustun nomi\",\"ustun nomi2\"]) ochishimiz mumkin:\n",
        "df=pd.read_csv(\"fayl/nomi\" index_col=0,names=[\"ustun nomi\",\"ustun nomi2\"])\n",
        "\n",
        "We can re-name column names as well while importing files:\n",
        "df=pd.read_csv(\"FileName\" index_col=0,names=[\"column name\",\"uscolumntun name2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdAkjv-DS_95"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkKftXjgTNlG"
      },
      "source": [
        "Agar fayl malumotlari \";\" orqali ajratilgan bo'lsa, buni ham fayl ochish jarayonida ko'rsatishim kerak bo'ladi:\n",
        "df=pd.read_csv(\"fayl/nomi\" index_col=0, sep=\";\")\n",
        "\n",
        "If a file elements are sepatated by [\";\"], we will have to mention it while opening a file:\n",
        "[ df=pd.read_csv(\"fileNa,e\" index_col=0, sep=\";\") ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ_-gwiuT4MR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKshqrNIT7-Y"
      },
      "source": [
        "Katta malumotlar bilan ishlaganda 10000 lab qatorlar bo'lsa, o;zimizga keraklicha qatorlarni(nrows=10) chaqirib olishimiz mumkin:\n",
        "[df=pd.read_csv(\"fayl/nomi\" index_col=0, nrows=10)]\n",
        "\n",
        "If a file contains Thousands of raws, we can import a certain amount of raws,showing an amount of raws while importing a new file:\n",
        "[df=pd.read_csv(\"fileName\" index_col=0, nrows=10)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk2WU3msW5z_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMMRBICQZz70"
      },
      "source": [
        "FAYLLARGA YOZISH.\n",
        "\n",
        "## Saving Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEgnw2AUaB7t"
      },
      "source": [
        "Ishlov berilgan df ni saqlash uchun df.to_csv(\"FaylningNomi\") yoki \n",
        "df.to_excel(\"FaylningNomi\") ko'rinishida saqlashimiz mumkin.\n",
        "\n",
        "In order to save a DataFrame, we can use following methods:\n",
        "[df.to_csv(\"FileName\")] or  df.to_excel(\"FileName\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWlvuEcEbKHC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY5ZydHtbT3o"
      },
      "source": [
        "Malum bir df dgi ustunni Series sifatida ajratib olib saqlab olish uchun esa:\n",
        "[ SeriesObj=df.ustunNomi ] >>>\n",
        ">> [ SeriesObj.to_cvs(\"SeriesObjectName.cvs\") ]\n",
        " \n",
        "\n",
        "Yuqorida saqlangan Series faylni qayta ochish jarayonida pandas ushbu faylni yana DataFrame ko'rinishida ochadi:\n",
        "pd.read_cvs(\"SeriesObjectName.cvs\").\n",
        "\n",
        "Bunday holatda bizga [squeeze=True] metodi yordam beradi. bu metod fayllarni Series ko'rinishida ochib beradi:\n",
        "pd.read_cvs(\"SeriesObjectName.cvs\" squeeze=True)\n",
        "LEKIN OCHILAYOTGAN FAYL FAQAT 2 TA USTUNDAN IBORAT BO'LISHI SHART!!\n",
        "\n",
        "We can save a certain column of a DataFrame as a Series object:\n",
        "to do that [ SeriesObj=df.columnName ]>>\n",
        ">> [ SeriesObj.to_cvs(\"SeriesObjectName.cvs\") ]\n",
        "\n",
        "While opening that Series file, pandas will open it outomatically as DataFrame [ pd.read_cvs(\"SeriesObjectName.cvs\") ]\n",
        "\n",
        "To avoid that, [squeeze=True] method needs to be used. It will help us to open that Series file as a Series, NOT as a dataframe. \n",
        "WE HAVE TO BE CAREFULL WHILE OPENING A FILE THRUOGH  [squeeze=True] METHOD, IT WILL WORK WHEN OUR FILE HAS ONLY 2 COLUMNS.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEWRttTMdmA2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XzDA6dPdm-Y"
      },
      "source": [
        "DataFrame ni excel ko'rinishida saqlash uchun esa:\n",
        "[df.to_(\"FaylNomi.xlsx\")] ko'rinishida saqlashimiz kerak.\n",
        "\n",
        "Saqlash jarayonida indexlarni tashlab yuborishimiz yoki o'zimizga kerakli ustunlarnigina saqlab olishimiz mumkin:\n",
        "[df.to_(\"FaylNomi.xlsx\", index=False, columns=[\"ustunN1\",\"ustunN2\",])\n",
        "\n",
        "To save a df as excel file: [ df.to_(\"FileName.xlsx\") ]\n",
        "We can drop OR re-name columns,drop index column([index=False]to save a memory), while seving our file:\n",
        "[df.to_(\"FileName.xlsx\", index=False, columns=[\"column1\",\"column2\",])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaWbl0y640Ld"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8vXG9jr41Rh"
      },
      "source": [
        "# HDF5 FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb-IOBCu80SE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydc115oC81u1"
      },
      "source": [
        "HDF5 formati ilmiy tadqiqodlar qilishda katta hajmdagi ma'lumotlarni saqlash uchun keng ioshlatiladigan formatlardan hisoblanadi.\n",
        "\n",
        "HDF5 fayllarni nafaqat Python,  balki Java, Julia, Matlab va boshqa dasturlash tillarida ochish mumkin va boshqa dasturlash tillarida ochish mumkin\n",
        "\n",
        "HDF - hierarchial data format (irarxiyali ma'lumotlar formati) hisoblanib, tarkibida bir nechta datasetlarni siqilgan holatda saqlashi mumkin.\n",
        "\n",
        "HDF formatida fayllarni saqlash uchun avval HDF obyketini yaratamiz:\n",
        "hdfobj = pd.HDFStore(\"mydata.h5\"=>>>name of a folder in our pc)\n",
        "\n",
        "hdf obyektiga ma;kumot qo'shish:\n",
        "hdfobj['uzdata'] = df       \n",
        "hdfobj['cardata'] = df2\n",
        "hdfobj['uzaholi'] = df['aholi']\n",
        "\n",
        "Obyekt ichidagi ma'umotlarga lug'at elementlariga murojaat qilgandek murojaat qilamiz:\n",
        "hdfobj['cardata']\n",
        "hdfobj['uzaholi']\n",
        "\n",
        "Ma'lumotlarni saqlab bo'lgach, .close() metodi yordamida faylni yopamiz:\n",
        "[hdfobj.close()]\n",
        "\n",
        "to_hdf() metodi yordamida DataFrameni to'g'ridan-to'g'ri .hdf faylga yozish mumkin.\n",
        "df.to_hdf('uzdata.h5',key='uzdata')\n",
        "\n",
        "HDF5 fayllarni o'qish uchun qaytadan HDFStore yoki read_hdf metodidan foydalanamiz:\n",
        "[ data = pd.HDFStore(\"mydata.h5\") ]\n",
        "data.keys()>>> output >>>> ['/cardata', '/uzaholi', '/uzdata']\n",
        " \n",
        "data['cardata'].head()\n",
        "\n",
        "read_hdf() metodidan foydalanish uchun dataset nomini (kalitini) ko'rsatish talab qilinadi: \n",
        "[df = pd.read_hdf('uzdata.h5', key='uzdata')]\n",
        "df\n",
        "\n",
        "              * * * * * * * * * * * * * * * * * * * * * * * * \n",
        "\n",
        "HDF5 format of the file is very comfortable to work with files which are in a big size.\n",
        "\n",
        "This type of files can be open not only in python, but also in Java, Julia, Matlab as well. \n",
        "\n",
        "HDF - is  hierarchial data format. It can be contained multiple squeezed data sets   \n",
        "\n",
        "In order to save files in HDF5, we will create HDF object first:\n",
        "hdfobj = pd.HDFStore(\"mydata.h5\">>>name of a folder in our pc)\n",
        "\n",
        "Adding data into our HDF object:\n",
        "hdfobj['uzdata'] = df\n",
        "hdfobj['cardata'] = df2\n",
        "hdfobj['uzaholi'] = df['aholi']\n",
        "\n",
        "To import data from HDF object, we will work like we used to work with Dictionaries:\n",
        "hdfobj['cardata']\n",
        "hdfobj['uzaholi']\n",
        "\n",
        "To save the object we will use : .close() method\n",
        "\n",
        "We can write and work directly with HDF file using [to_hdf()] method.\n",
        "df.to_hdf('uzdata.h5',key='uzdata')\n",
        "\n",
        "\n",
        "re-read hdf files  HDFStore OR read_hdf:\n",
        "[data = pd.HDFStore(\"mydata.h5\")]\n",
        "data.keys()>>> output >>>> ['/cardata', '/uzaholi', '/uzdata']\n",
        "\n",
        "To use read_hdf() method, we have to write key name of the dataset:\n",
        "[df = pd.read_hdf('uzdata.h5', key='uzdata')]\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzywvcdMYR4s"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fevxpgB4YXPr"
      },
      "source": [
        "# Reading a file from web pages\n",
        "Online dagi turli jadvallarni pd.read_html metodi orqali ko'chirib olishimiz mumkin. Etiborli tarafi bu yo'l web sahifadagi barcha jadvallarni ko'chirib oladi:\n",
        "pd.read_html(\"https://webPageName\")\n",
        "\n",
        "\n",
        "pd.read_html(\"https://webPageName\"): This method hepls us to import online html tables. BUT IT WILL IMPORT ALL THE TABLES FROM WEB PAGE.\n",
        "\n",
        "We will save ir as a new variable: \n",
        "df=pd.read_html(\"https://webPageName\") \n",
        "\n",
        "To see how many tables or dataframes it contains: len(df)\n",
        "\n",
        "to see the dataframes of the variable df[n]>> n= number of the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tD6NIuZMzcTK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGMzXFWp0r7h"
      },
      "source": [
        "# sqlite omboriga ulanish !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5KrvLgn03PZ"
      },
      "source": [
        "This method [!wget https://www.webPageName] helps us to connec database:\n",
        "!wget https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HolsP4BP02HD",
        "outputId": "b51b7a97-6c10-4011-ede8-3d67f319bb7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-27 00:50:41--  https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip\n",
            "Resolving www.sqlitetutorial.net (www.sqlitetutorial.net)... 151.139.128.11\n",
            "Connecting to www.sqlitetutorial.net (www.sqlitetutorial.net)|151.139.128.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305596 (298K) [application/zip]\n",
            "Saving to: ‘chinook.zip.1’\n",
            "\n",
            "\rchinook.zip.1         0%[                    ]       0  --.-KB/s               \rchinook.zip.1       100%[===================>] 298.43K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-07-27 00:50:42 (16.9 MB/s) - ‘chinook.zip.1’ saved [305596/305596]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!wget https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDQKLdme2Njz"
      },
      "source": [
        "In our case we have zip file. to execute or open it following method will be perfect:\n",
        "[!unzip chinook.zip]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip chinook.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz5WaWIA_Ab6",
        "outputId": "b38a2c8d-2713-4dc8-886d-5397ea1c09fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  chinook.zip\n",
            "  inflating: chinook.db              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db =sql.connect(\"chinook.db\")\n",
        "cursor=db.cursor()\n"
      ],
      "metadata": {
        "id": "S471Rdqz6Go6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\") # REading all the tables from database.\n",
        "cursor.fetchall()                                                    # fetchall>>fetchmany()>>fetchone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYKdJaxm6104",
        "outputId": "22ece0a4-e960-4d67-81df-b52af8de3cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('albums',),\n",
              " ('sqlite_sequence',),\n",
              " ('artists',),\n",
              " ('customers',),\n",
              " ('employees',),\n",
              " ('genres',),\n",
              " ('invoices',),\n",
              " ('invoice_items',),\n",
              " ('media_types',),\n",
              " ('playlists',),\n",
              " ('playlist_track',),\n",
              " ('tracks',),\n",
              " ('sqlite_stat1',)]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cursor.execute(\"SELECT COUNT (*) FROM employees\")\n",
        "cursor.fetchone() # we can see that we have 8 employees"
      ],
      "metadata": {
        "id": "CvcWh_Y18gpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb24def-dc76-4c71-fba5-8c3fa9d3afbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8,)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gpU_1pBgDGob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cursor.execute(\"PRAGMA table_info(customers);\")\n",
        "cursor.fetchall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j8Ws1f5DPLO",
        "outputId": "7406dab5-f4a2-4cd8-f197-74b9a2929c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'CustomerId', 'INTEGER', 1, None, 1),\n",
              " (1, 'FirstName', 'NVARCHAR(40)', 1, None, 0),\n",
              " (2, 'LastName', 'NVARCHAR(20)', 1, None, 0),\n",
              " (3, 'Company', 'NVARCHAR(80)', 0, None, 0),\n",
              " (4, 'Address', 'NVARCHAR(70)', 0, None, 0),\n",
              " (5, 'City', 'NVARCHAR(40)', 0, None, 0),\n",
              " (6, 'State', 'NVARCHAR(40)', 0, None, 0),\n",
              " (7, 'Country', 'NVARCHAR(40)', 0, None, 0),\n",
              " (8, 'PostalCode', 'NVARCHAR(10)', 0, None, 0),\n",
              " (9, 'Phone', 'NVARCHAR(24)', 0, None, 0),\n",
              " (10, 'Fax', 'NVARCHAR(24)', 0, None, 0),\n",
              " (11, 'Email', 'NVARCHAR(60)', 1, None, 0),\n",
              " (12, 'SupportRepId', 'INTEGER', 0, None, 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-r2TOVYSDm-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## READING A TABLE FROM SQL DATABASE AND CONVERTING IT INTO DATAFRAME !"
      ],
      "metadata": {
        "id": "G8R7-3koLry6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_Oud94JvL7C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "415DJ9rVL1ht"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "3.1-BOLIM-MALUMOTLARGA-ISHLOV BERISH-DATA BASE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPy776zepAYc8pLx0nSe8B8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}